{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9094729,"sourceType":"datasetVersion","datasetId":5488435}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\ndt = pd.read_json(\"/kaggle/input/data-set-n/case_2_data_for_members .json\")\nprint(dt.head())","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-03T18:17:29.406972Z","iopub.execute_input":"2024-08-03T18:17:29.408105Z","iopub.status.idle":"2024-08-03T18:17:30.174896Z","shell.execute_reply.started":"2024-08-03T18:17:29.408049Z","shell.execute_reply":"2024-08-03T18:17:30.173373Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"                                             vacancy  \\\n0  {'uuid': '779f3a59-206a-3241-adc4-d7db504f960b...   \n1  {'uuid': '7a4813fc-43bc-3896-a607-4c8682b01002...   \n2  {'uuid': 'c03085c3-9b1e-3564-bb1e-59aa72e5fbca...   \n3  {'uuid': 'a8dd83c3-178d-3c70-90c2-7c3648f6b96a...   \n4  {'uuid': '9d98eba0-13bb-38d3-b742-4fd445954b3d...   \n\n                                      failed_resumes  \\\n0  [{'uuid': '74392e00-ecfb-335b-9fc1-c2652dca06e...   \n1  [{'uuid': '254487e1-81ba-3f2b-9f15-eba98d891ef...   \n2  [{'uuid': '8746a855-022c-34d4-9b55-58da5483c25...   \n3  [{'uuid': '557c9b5b-9707-360b-bb1f-18c3c1b9439...   \n4  [{'uuid': '821b6466-f3e2-37c9-b44f-676d91bde04...   \n\n                                   confirmed_resumes  \n0  [{'uuid': '8c8cf797-2c6b-3f4b-b28b-20d57bd88b8...  \n1  [{'uuid': '23ca55a4-2257-3cbc-a34f-d5e1b98d8c2...  \n2  [{'uuid': '95cd87f6-0495-36e5-adad-0782a1ac435...  \n3  [{'uuid': '077836a8-16a8-34f1-a192-fe82ebc8bc9...  \n4  [{'uuid': '2e517375-ff7d-3781-ae5c-2b0784dbc2b...  \n","output_type":"stream"}]},{"cell_type":"code","source":"dt['vacancy'][0]","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:50:55.940734Z","iopub.execute_input":"2024-08-03T18:50:55.941321Z","iopub.status.idle":"2024-08-03T18:50:55.950179Z","shell.execute_reply.started":"2024-08-03T18:50:55.941263Z","shell.execute_reply":"2024-08-03T18:50:55.948842Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"{'uuid': '779f3a59-206a-3241-adc4-d7db504f960b',\n 'name': 'Java разработчик команда Инвестиции',\n 'keywords': None,\n 'description': ' Описание Мы расширяем команды и ищем разработчиков для развития нескольких сервисов:   Инвестиции. Мы — лидер среди брокеров по количеству активных клиентов. Делаем инвестиции удобными, технологичными и понятными;   Бизнес. Меняем подход к ведению бухгалтерии, обмену документами между организациями и работе с архивами — переводим все и вся в цифру;   Страхование. Развиваем платформу прямых продаж. Наша цель — предсказуемый, удобный процесс для бизнеса и клиента; Платежные технологии и процессинг. Занимаемся разработкой и поддержкой платежного шлюза банка. Задачи шлюза — определять тип платежей, наполнять их данными из других систем банка и проверять разрешенность операций. У нас много интересных и разнообразных задач, опытная команда и отличные возможности для роста. Откликайтесь на вакансию, чтобы узнать о проектах и выбрать подходящий для вас. Требования Опыт разработки на Java от 3 лет Опыт коммерческой разработки на Java 11+ или Kotlin Опыт коммерческой разработки с любым из фреймворков: Spring Boot, Quarkus, Micronaut или Vert.x Опыт коммерческой разработки с одним из контейнеризаторов: Kubernetes, Docker или OpenShift Опыт коммерческой разработки с одним из брокеров: Kafka, Rabbit MQ или Active MQ Опыт коммерческой разработки с Postgress, MySQL или Oracle будет плюсом Опыт работы с системой контроля версий Мы предлагаем Работу в офисе или удаленно — по договоренности Возможность работы в аккредитованной ИТ-компании Платформу обучения и развития «  Апгрейд». Курсы, тренинги, вебинары и базы знаний. Поддержку менторов и наставников, помощь в поиске точек роста и карьерном развитии Заботу о здоровье. Оформим полис ДМС со стоматологией и страховку от несчастных случаев. Предложим льготное страхование вашим близким Бесплатный фитнес-зал или компенсацию затрат на спортивные занятия 3 дополнительных дня отпуска в год Уникальную well-being-программу, направленную на физическое и ментальное благополучие сотрудников Достойную зарплату — обсудим ее на собеседовании ',\n 'comment': '450 на руки'}"},"metadata":{}}]},{"cell_type":"code","source":"dt['confirmed_resumes'][2][0]","metadata":{"execution":{"iopub.status.busy":"2024-08-03T19:01:17.814445Z","iopub.execute_input":"2024-08-03T19:01:17.814874Z","iopub.status.idle":"2024-08-03T19:01:17.828681Z","shell.execute_reply.started":"2024-08-03T19:01:17.814839Z","shell.execute_reply":"2024-08-03T19:01:17.826771Z"},"trusted":true},"execution_count":66,"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"{'uuid': '95cd87f6-0495-36e5-adad-0782a1ac4351',\n 'first_name': 'Игнат',\n 'last_name': 'Галкина',\n 'birth_date': '1978-05-07',\n 'country': 'Россия',\n 'city': 'Муром',\n 'about': None,\n 'key_skills': 'Обучаемость, Исполнительность, Работа в команде, Индивидуальная работа, Аналитическое мышление, Работа с большим объемом информации, Статистический анализ, Аналитические исследования, Деловая коммуникация, Подготовка докладов и выступлений, Работа с базами данных, MS SQL, Transact-SQL, Анализ бизнес-процессов, Реинжиниринг бизнес-процессов, PDM / PLM, MRP II / ERP, Автоматизация производства, Функциональное тестирование, Модульное тестирование,  ирование пользовательского интерфейса, Разработка технических заданий, Техническая документация, Анализ и оптимизация SQL-запросов, Анализ чужого кода, Code-review, MS Excel, MS Access, Обучение персонала',\n 'experienceItem': [{'starts': '2023-04-01',\n   'ends': None,\n   'employer': 'МФО ЖелДор',\n   'city': 'Раменское',\n   'position': 'системный аналитик DWH',\n   'description': ' сбор, систематизация и проработка требований заказчиков преобразование требований в функциональные и технические спецификации для дальнейшей передачи их в разработку подготовка проектной документации (функциональные требования, технические задания и решения, спецификации, инструкции и т.д.), постановка задач на разработку изучение и анализ источников данных и взаимосвязей, возможностей их извлечения, обогащения и очистки Презентация доработок заказчикам и заинтересованным подразделениям на приемо-сдаточных испытаниях Подготовка прототипов витрин и отчетных форм создание постановки и маппингов S2T '},\n  {'starts': '2018-09-01',\n   'ends': '2023-04-01',\n   'employer': 'МФО ДизайнТекстиль',\n   'city': 'Серпухов',\n   'position': 'Главный специалист отдела развития хранилища данных и систем интеграции',\n   'description': 'Аналитика бизнес-процессов и подготовка предложений по реализации/изменению систем и отчётов. Реализация новых, внесение изменений и расширение функционала уже существующих систем и отчётов. Реализация выходных печатных форм. Разработка сложных запросов и процедур на Т-SQL. Анализ и редактирование существующих запросов, процедур и функций на T-SQL. Анализ быстродействия SQL-запросов и процедур, выявление критических ресурсоёмких частей и их оптимизация. Предоставление результатов SQL-запросов в формате CSV и XML. Импорт/экспорт данных Хранилища и БД. Проверка загруженных данных на Хранилище и их синхронизация с исходными БД.'},\n  {'starts': '2016-02-01',\n   'ends': '2018-09-01',\n   'employer': 'ОАО РадиоСеверОбл',\n   'city': 'Домодедово',\n   'position': 'Специалист отдела консолидации данных',\n   'description': 'Подготовка предложений по реализации систем и отчётов. Реализация новых и расширение функционала уже существующих систем и отчётов. Реализация выходных печатных форм. Разработка запросов, процедур и функций на T-SQL. Анализ быстродействия своих SQL-запросов и процедур, выявление критических ресурсоёмких частей и их оптимизация.'},\n  {'starts': '2011-07-01',\n   'ends': '2016-01-01',\n   'employer': 'ОАО СервисСтройЛенТрест',\n   'city': 'Можайск',\n   'position': 'Начальник бюро Автоматизации производства отдела АСУП',\n   'description': 'Внедрение САУП ГОЛЬФСТРИМ: - по укрупнённому планированию, сводной производственной программе предприятия и межцеховому планированию изготовления ДСЕ; - по учёту номенклатуры ДСЕ и ТМЦ на складах и цеховых кладовых; - по учёту выполненых работ по сдельным нарядам; - по расчёту экономических нормативов по ДСЕ и изделиям. Оптимизация и доработка внедряемой САУП ГОЛЬФСТРИМ под специфику работы предприятия. Взаимодействие САУП ГОЛЬФСТРИМ с 1C:КА по импорту/экспорту данных по номенклатуре, рабочим нарядам, приобретённым ТМЦ и т.п. Настройка и реализация БД Архива предприятия по производственным заказам. Реализация SQL-запросов к БД для получени сводной информации по производственным заказа в дополнении к стандартным возможностям САУП. Анализ изменений данных, процедур и функций по журналу БД.'},\n  {'starts': '2010-01-01',\n   'ends': '2011-07-01',\n   'employer': 'ОАО Асбоцемент',\n   'city': 'Серебряные Пруды',\n   'position': 'Начальник бюро Оптимальных методов управления отдела АСУП',\n   'description': 'Анализ современных методологий моделирования бизнес-процессов. Анализ минимально-необходимого уровня внедрения Системы автоматизированного управления произвдством. Моделирование и реинжиниринг бизнес-процессов предприятия для внедрения САУП ГОЛЬФСТРИМ: - по укрупнённому планированию, сводной производственной программе предприятия и межцеховому планированию изготовления ДСЕ; - по учёту номенклатуры ДСЕ и ТМЦ на складах и цеховых кладовых; - по учёту выполненых работ по сдельным нарядам; - по расчёту экономических нормативов по ДСЕ и изделиям.'},\n  {'starts': '2008-10-01',\n   'ends': '2010-01-01',\n   'employer': 'МФО Cиб',\n   'city': 'Можайск',\n   'position': 'Начальник бюро Автоматизации конструкторско-технологической подготовки произвлодства отдела АСУП',\n   'description': 'Администрирование системы ЛОЦМАН:PLM. Перевод нормативной БД КТПП предприятия в ЛОЦМАН:PLM. Адаптация внедряемой системы ЛОЦМАН:PLM под специфику данных КТПП предприятия. Разработка структуры таблиц для расширения БД, анализ данных и адаптация ЛОЦМАН:PLM для работы с изменениями по составу изделий с отложенным сроком актуализации.'},\n  {'starts': '2008-02-01',\n   'ends': '2008-10-01',\n   'employer': 'МКК ВостокCиб',\n   'city': 'Балашиха',\n   'position': 'Математик II категории',\n   'description': 'Анализ имеющейся на предприятии системы КТПП. Изучение возможностей готовящейся к внедрению на прелдприятии системы ЛОЦМАН:PLM и определение уровня адаптации данной системы под нужны КТПП предприятия. Обучение администрированию ЛОЦМАН:PLM.'},\n  {'starts': '2001-04-01',\n   'ends': '2008-02-01',\n   'employer': 'МКК Флот',\n   'city': 'Можайск',\n   'position': 'Инженер-технолог II категории отдела ВЭСиВЗ',\n   'description': 'Разработка и внедрение МаИС дял анализа участия предприятия в тендерах МО РФ. Разработка и внедрение программы по учёту на складах, отгрузке и подготовке сопроводительной документации по договорам.'},\n  {'starts': '2001-02-01',\n   'ends': '2004-04-01',\n   'employer': 'МФО РемИнфо',\n   'city': 'Дорохово',\n   'position': 'Инженер-технолог III категории отдела ВЗ',\n   'description': 'Планировка и перепланировка участкой и цехов предприятия. Автоматизация подготовки производства. Подготовк технической документации.'},\n  {'starts': '2000-05-01',\n   'ends': '2000-12-01',\n   'employer': 'ЗАО ВодЮпитерТекстильТраст',\n   'city': 'Мытищи',\n   'position': 'Программист',\n   'description': 'Разработка отчётов и бланков печатных форм для 1С:\"Торговля\" и 1С:\"Склад\".'}],\n 'languageItem': ['Русский', 'Английский'],\n 'educationItem': [{'year': 2004,\n   'organization': 'Муромский институт (филиал) Владимирского государственного университета им. А.Г. и Н.Г. Столетовых, Муром',\n   'faculty': 'Факультет экономики и менеджмента',\n   'specialty': 'Экономика и управление на предприятии',\n   'result': '',\n   'education_type': 'Основное',\n   'education_level': 'Высшее'},\n  {'year': 2000,\n   'organization': 'Владимирский государственный университет им. А.Г. и Н.Г. Столетовых, Владимир',\n   'faculty': 'Радиотехнический факультет',\n   'specialty': 'Информационные системы (в управлении предприятий, в экономике)',\n   'result': '',\n   'education_type': 'Основное',\n   'education_level': 'Высшее'}]}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Создаю датасет для проведения исследований из другого датасета","metadata":{}},{"cell_type":"code","source":"title = pd.DataFrame(columns=['0'])\nvacancy = pd.DataFrame(columns=['0'])\npersons = pd.DataFrame(columns=['0'])","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:47:51.737719Z","iopub.execute_input":"2024-08-03T18:47:51.738150Z","iopub.status.idle":"2024-08-03T18:47:51.746573Z","shell.execute_reply.started":"2024-08-03T18:47:51.738119Z","shell.execute_reply":"2024-08-03T18:47:51.745051Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"vac = pd.DataFrame(columns=['0'])\ntitl = pd.DataFrame(columns=['0'])\nfor i in range(len(dt['vacancy'])):\n    titl.loc[len(titl.index)] = dt['vacancy'][i]['name']\n    vac.loc[len(vac.index)] = dt['vacancy'][i]['name'] + \" \" + str(dt['vacancy'][i]['description'])\nvac_ = vac['0'].tolist()\ntitl_ = titl['0'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:46:41.916191Z","iopub.execute_input":"2024-08-03T18:46:41.916739Z","iopub.status.idle":"2024-08-03T18:46:41.990788Z","shell.execute_reply.started":"2024-08-03T18:46:41.916696Z","shell.execute_reply":"2024-08-03T18:46:41.989012Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"for i in range(len(dt['confirmed_resumes'])):\n    for j in range(len(dt['confirmed_resumes'][i])):\n        if not dt['confirmed_resumes'][i][j].get('experienceItem'):\n            continue\n        for k in range(len(dt['confirmed_resumes'][i][j]['experienceItem'])):\n            title.loc[len(title.index)] = dt['confirmed_resumes'][i][j]['experienceItem'][k]['position']\n            vacancy.loc[len(vacancy.index)] = dt['confirmed_resumes'][i][j]['experienceItem'][k]['position'] + \" \" + str(dt['confirmed_resumes'][i][j]['experienceItem'][k]['description'])\n            persons.loc[len(persons.index)] = dt['confirmed_resumes'][i][j]['uuid']\n            \nfor i in range(len(dt['failed_resumes'])):\n    for j in range(len(dt['failed_resumes'][i])):\n        if not dt['failed_resumes'][i][j].get('experienceItem'):\n            continue\n        for k in range(len(dt['failed_resumes'][i][j]['experienceItem'])):\n            title.loc[len(title.index)] = dt['failed_resumes'][i][j]['experienceItem'][k]['position']\n            vacancy.loc[len(vacancy.index)] = dt['failed_resumes'][i][j]['experienceItem'][k]['position'] + \" \" + str(dt['failed_resumes'][i][j]['experienceItem'][k]['description'])\n            persons.loc[len(persons.index)] = dt['failed_resumes'][i][j]['uuid']","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:47:53.817155Z","iopub.execute_input":"2024-08-03T18:47:53.817595Z","iopub.status.idle":"2024-08-03T18:48:01.164605Z","shell.execute_reply.started":"2024-08-03T18:47:53.817561Z","shell.execute_reply":"2024-08-03T18:48:01.163391Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"title = title['0'].tolist()\nvacancy = vacancy['0'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:48:01.166844Z","iopub.execute_input":"2024-08-03T18:48:01.167323Z","iopub.status.idle":"2024-08-03T18:48:01.175330Z","shell.execute_reply.started":"2024-08-03T18:48:01.167281Z","shell.execute_reply":"2024-08-03T18:48:01.173656Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"# Векторизация и очистка текстовых данных","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel, cosine_similarity","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:19:57.641017Z","iopub.execute_input":"2024-08-03T18:19:57.641473Z","iopub.status.idle":"2024-08-03T18:19:57.664595Z","shell.execute_reply.started":"2024-08-03T18:19:57.641438Z","shell.execute_reply":"2024-08-03T18:19:57.663210Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"!pip install pymorphy2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\nimport pymorphy2\nimport nltk\nimport re\nfrom gensim import models\nimport string\nnltk.download('punkt')\nnltk.download('stopwords')\nstop_words = stopwords.words(\"russian\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocessing(text):\n    text = text.lower()\n    tokens = word_tokenize(text, language=\"russian\")\n    filtered_tokens = []\n    snowball = SnowballStemmer(language=\"russian\")\n    morph = pymorphy2.MorphAnalyzer()\n\n    for token in tokens:\n        if token not in stop_words:\n            token = token.strip(string.punctuation)\n            token = snowball.stem(morph.parse(token)[0].normal_form)\n            if token != '':\n                filtered_tokens.append(token)\n\n    return ' '.join(filtered_tokens)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = vac_.copy()\nfor i in range(len(text)):\n    if i % 100 == 0:\n        print(f'Progress {i/len(text)*100}%')\n    text[i] = preprocessing(text[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2), min_df=0)\ntfidf_matrix = tf.fit_transform(text)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"persons = persons['0'].tolist() \ntitle = title['0'].tolist() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame({'title': title, 'vacancy': vacancy, 'persons': persons})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# сравниваю аоступающий запрос с резюме из базы данных и сортирую базу данных в порядке убывания (от подходящей до не подходящей)","metadata":{}},{"cell_type":"code","source":"from nltk.tokenize import word_tokenize\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n\ndef vectorize_and_rank(input_sentence, sentences, titl):\n    # Токенизируем входное предложение\n    input_tokens = word_tokenize(input_sentence.lower())\n\n    # Векторизуем все предложения (включая входное)\n    all_sentences = [input_sentence] + sentences\n    count_vectorizer = CountVectorizer()\n    sentence_vectors = count_vectorizer.fit_transform(all_sentences)\n    \n    # Вычисляем косинусное сходство между входным предложением и всеми остальными\n    similarities = cosine_similarity(sentence_vectors[0].reshape(-1, 1), sentence_vectors[1:].reshape(-1, 1)).flatten()\n\n    # Создаем упорядоченный ранжированный список\n    ranked_sentences = sorted(list(zip(titl, similarities)), key=lambda x: x[1], reverse=True)\n\n    return [x[0] for x in ranked_sentences]\n\n\ninput_sentence = vac_[20]\nother_sentences = vacancy\n\nranked_sentences = vectorize_and_rank(input_sentence, other_sentences, title)\nprint(f'For \"{titl_[20]}\" vacancy: ', '\\n')\nfor idx, sentence in enumerate(ranked_sentences):\n    print(f\"{idx+1}. {sentence}\")\n    if idx == 10:\n        break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Проверка другого метода векторизации, через LLM модели (RuBERT и LaBSE)\n\n","metadata":{}},{"cell_type":"code","source":"pip install -U sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2024-08-03T18:17:11.022072Z","iopub.execute_input":"2024-08-03T18:17:11.022553Z","iopub.status.idle":"2024-08-03T18:17:29.404238Z","shell.execute_reply.started":"2024-08-03T18:17:11.022518Z","shell.execute_reply":"2024-08-03T18:17:29.402865Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.42.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2+cpu)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.23.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence-transformers) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-3.0.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('cointegrated/rubert-tiny2')","metadata":{"execution":{"iopub.status.busy":"2024-08-03T19:19:36.736122Z","iopub.execute_input":"2024-08-03T19:19:36.736598Z","iopub.status.idle":"2024-08-03T19:19:38.034986Z","shell.execute_reply.started":"2024-08-03T19:19:36.736563Z","shell.execute_reply":"2024-08-03T19:19:38.033848Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"vacancy[60]","metadata":{"execution":{"iopub.status.busy":"2024-08-03T19:08:53.335839Z","iopub.execute_input":"2024-08-03T19:08:53.336313Z","iopub.status.idle":"2024-08-03T19:08:53.344022Z","shell.execute_reply.started":"2024-08-03T19:08:53.336279Z","shell.execute_reply":"2024-08-03T19:08:53.342707Z"},"trusted":true},"execution_count":76,"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"'Начальник бюро Автоматизации конструкторско-технологической подготовки произвлодства отдела АСУП Администрирование системы ЛОЦМАН:PLM. Перевод нормативной БД КТПП предприятия в ЛОЦМАН:PLM. Адаптация внедряемой системы ЛОЦМАН:PLM под специфику данных КТПП предприятия. Разработка структуры таблиц для расширения БД, анализ данных и адаптация ЛОЦМАН:PLM для работы с изменениями по составу изделий с отложенным сроком актуализации.'"},"metadata":{}}]},{"cell_type":"code","source":"# векторизация всех предложений через нейросеть\ninput_sentence = vacancy[10]\nother_sentences = vac_\nsentence = [input_sentence] + other_sentences\nsentences = model.encode(sentence)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T19:20:36.789273Z","iopub.execute_input":"2024-08-03T19:20:36.789702Z","iopub.status.idle":"2024-08-03T19:20:56.156395Z","shell.execute_reply.started":"2024-08-03T19:20:36.789665Z","shell.execute_reply":"2024-08-03T19:20:56.154925Z"},"trusted":true},"execution_count":101,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2820327cdc04c66a99abf82f3ae73a5"}},"metadata":{}}]},{"cell_type":"code","source":"def vectorize_and_rank(sentences, titl):\n    # Вычисляем косинусное сходство между входным предложением и всеми остальными\n    similarities = cosine_similarity([sentences[0]], sentences[1:]).flatten()\n    # Создаем упорядоченный ранжированный список\n    ranked_sentences = sorted(list(zip(titl, similarities)), key=lambda x: x[1], reverse=True)\n    return [x[0] for x in ranked_sentences]\n\nranked_sentences = vectorize_and_rank(sentences, titl_)\nprint(f'For \"{title[10]}\" vacancy: ', '\\n')\nfor idx, sentence in enumerate(ranked_sentences):\n    print(f\"{idx+1}. {sentence}\")\n    if idx == 25:\n        break","metadata":{"execution":{"iopub.status.busy":"2024-08-03T19:20:56.159543Z","iopub.execute_input":"2024-08-03T19:20:56.160083Z","iopub.status.idle":"2024-08-03T19:20:56.172037Z","shell.execute_reply.started":"2024-08-03T19:20:56.160036Z","shell.execute_reply":"2024-08-03T19:20:56.170852Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stdout","text":"For \"Teamlead\" vacancy:  \n\n1. ИТ-лидер\n2. Senior Java-разработчик проект брокерское обслуживание \n3. DevOps инженер\n4. Java-разработчик\n5.  Тестировщик\n6. Java-разработчик проект АБС\n7. ETL Разработчик (ДИР)\n8. Системный аналитик\n9. Ведущий/ Главный аналитик DWH\n10. Руководитель группы разработки\n11. Системный аналитик\n12. Frontend Developer \n13. Java разработчик команда Инвестиции\n14. Аналитик DWH \"Hadoop\"\n15. Python Developer\n16. DevOps\n17. ИТ-Лидер команды\n18. Java-разработчик\n19. Системный аналитик финтех\n20. Архитектор/Системный аналитик DWH ДИР\n21. Java developer\n22. Java разработчик senior\n23. Аналитик DWH\n24. Senior Java-разработчик\n25. Системный аналитик комманда Залоги\n26. Ведущий разработчик ETL \"Hadoop\" \n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Использование нейросети LaBSE","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nmodel1 = SentenceTransformer('sentence-transformers/LaBSE')","metadata":{"execution":{"iopub.status.busy":"2024-08-03T19:17:36.374933Z","iopub.execute_input":"2024-08-03T19:17:36.375344Z","iopub.status.idle":"2024-08-03T19:17:41.019953Z","shell.execute_reply.started":"2024-08-03T19:17:36.375314Z","shell.execute_reply":"2024-08-03T19:17:41.018636Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"# векторизация всех предложений через нейросеть\ninput_sentence = vacancy[10]\nother_sentences = vac_\nsentence = [input_sentence] + other_sentences\nsentence_v = model1.encode(sentence)","metadata":{"execution":{"iopub.status.busy":"2024-08-03T19:18:55.832659Z","iopub.execute_input":"2024-08-03T19:18:55.833196Z","iopub.status.idle":"2024-08-03T19:19:09.641231Z","shell.execute_reply.started":"2024-08-03T19:18:55.833159Z","shell.execute_reply":"2024-08-03T19:19:09.639916Z"},"trusted":true},"execution_count":95,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f62e3bf6bbf74451a85b65029282a986"}},"metadata":{}}]},{"cell_type":"code","source":"def vectorize_and_rank(sentences, titl):\n    similarities = cosine_similarity([sentences[0]], sentences[1:]).flatten()\n    # Создаем упорядоченный ранжированный список\n    ranked_sentences = sorted(list(zip(titl, similarities)), key=lambda x: x[1], reverse=True)\n    return [x[0] for x in ranked_sentences]\n\n# Пример использования\n\nranked_sentences = vectorize_and_rank(sentence_v, titl_)\nprint(f'For \"{title[10]}\" vacancy: ', '\\n')\nfor idx, sentence in enumerate(ranked_sentences):\n    print(f\"{idx+1}. {sentence}\")\n    if idx == 25:\n        break","metadata":{"execution":{"iopub.status.busy":"2024-08-03T19:19:09.643420Z","iopub.execute_input":"2024-08-03T19:19:09.643880Z","iopub.status.idle":"2024-08-03T19:19:09.656777Z","shell.execute_reply.started":"2024-08-03T19:19:09.643777Z","shell.execute_reply":"2024-08-03T19:19:09.655244Z"},"trusted":true},"execution_count":96,"outputs":[{"name":"stdout","text":"For \"Teamlead\" vacancy:  \n\n1. ETL Разработчик (ДИР)\n2. Ведущий разработчик ETL \"Hadoop\" \n3. Java-разработчик проект АБС\n4. ИТ-лидер\n5. DevOps инженер\n6. Системный аналитик финтех\n7. Java-разработчик\n8. Java разработчик команда Инвестиции\n9.  Тестировщик\n10. Аналитик DWH \"Hadoop\"\n11. Senior Java-разработчик проект брокерское обслуживание \n12. Аналитик DWH\n13. Java-разработчик\n14. DevOps\n15. Java developer\n16. Архитектор/Системный аналитик DWH ДИР\n17. Руководитель группы разработки\n18. Java разработчик senior\n19. Python Developer\n20. Ведущий/ Главный аналитик DWH\n21. Системный аналитик\n22. ИТ-Лидер команды\n23. Системный аналитик\n24. Senior Java-разработчик\n25. Frontend Developer \n26. Системный аналитик комманда Залоги\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Функции для парсинга документов типа JSON, которые поступают на вход модели: резюме сотрудника и базы данных из всех вакансий ","metadata":{}},{"cell_type":"code","source":"def parsing_person(path):\n    # в data можно поместить словарь с одним пользователем или считать из json файла, который подадут на вход\n    # data = pd.read_json(path)\n    data = path\n    result = ' '\n    for i in range(len(data['professions'])):\n        result += str(data['professions'][i]['profession_name']) + \" \"\n    result += str(data['about_me'])\n    return result","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def parsing_objects(path):\n    # в data можно поместить словарь с вакансиями или считать из json файла, который подадут на вход\n    # data = pd.read_json(path)\n    data = path\n    result = pd.DataFrame(columns=['0'])\n    title = pd.DataFrame(columns=['0'])\n    id_lst = pd.DataFrame(columns=['0'])\n    for i in range(len(data['objects_constructions'])):\n        id_lst.loc[len(id_lst.index)] = data['objects_constructions'][i]['id']\n        title.loc[len(title.index)] = data['objects_constructions'][i]['work_name']\n        s = ''\n        for j in range(len(data['objects_constructions'][i]['professions'])):\n            s += data['objects_constructions'][i]['professions'][j]['profession_name'] + \" \"\n        result.loc[len(result.index)] = str(data['objects_constructions'][i]['work_name']).lower() + \" \" + s + str(data['objects_constructions'][i]['work_description']).lower()\n    # возвращает датафрейм, хранящий id, название профессии и её описание\n    dt = pd.DataFrame({'id': id_lst['0'].tolist(), 'title': title['0'].tolist(), 'vacancy': result['0'].tolist()})\n    return dt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def back_to_back(lst, path):\n    # повторно считываю весь словарь профессий, его можно напрямую в data сюда передать\n    # data = pd.read_json(path)\n    data = path\n    res = {'objects_constructions': []}\n    for el in lst:\n        for c in range(len(data['objects_constructions'])):\n            if data['objects_constructions'][c]['id'] == el:\n                res['objects_constructions'].append(data['objects_constructions'][c])\n                break\n    # возвращает отсортированный словарь профессий, по списку подходящих пользователю вакансий\n    return res","metadata":{},"execution_count":null,"outputs":[]}]}
